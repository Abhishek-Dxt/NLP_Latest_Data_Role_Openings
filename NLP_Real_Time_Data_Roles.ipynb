{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd724cc0",
   "metadata": {},
   "source": [
    "## Building a LinkedIn Job Description Scraper - \n",
    "\n",
    "(Check Scraping_descriptions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb319eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cfscrape\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9081297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linkedin_job_description(job_id):\n",
    "    job_url = f'https://www.linkedin.com/jobs/view/{job_id}/'\n",
    "    scraper = cfscrape.create_scraper()\n",
    "    response = scraper.get(job_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        description_div = soup.find('div', class_='description__text description__text--rich')\n",
    "        job_description = description_div.get_text(strip=True) if description_div else \"No job description found\"\n",
    "        return job_description\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        return None\n",
    "    \n",
    "def job_data_collector(job_role):\n",
    "    target_url = f'https://api.scrapingdog.com/linkedinjobs?api_key=655be462fcb45d3c89d2a0bf&field={job_role}&geoid=103644278&page=1'\n",
    "    resp = requests.get(target_url).json()\n",
    "    job_id_list = []\n",
    "    for i in resp:\n",
    "        if 'job_id' in i:\n",
    "            job_id_list.append(i['job_id'])\n",
    "    \n",
    "    job_data = ''\n",
    "    for job_id in job_id_list[:25]:\n",
    "        if len(get_linkedin_job_description(job_id)) < 7000:\n",
    "            job_data += get_linkedin_job_description(job_id)\n",
    "    \n",
    "    return job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32f64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5887893",
   "metadata": {},
   "source": [
    "### Collecting 25 latest Job Descriptions for the following 4 roles - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83659ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_data = job_data_collector('Data%20Analyst')\n",
    "ds_data = job_data_collector('Data%20Scientist')\n",
    "de_data = job_data_collector('Data%20Engineer')\n",
    "ml_data = job_data_collector('Machine%20Learning%20Engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7504c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Position PurposeA Data Analyst Supply Chain leverages technical abilities to synthesize complex analytical tasks into easily understood data-driven stories. Responsible for working collaboratively with other analysts to apply established analytical processes on diverse datasets to deduce insights and solve real-world business problems. Also ensures that all reporting and analytical responsibilities are completed competently in a timely manner, continually seeking out opportunities to hone existing technical skills (e.g. writing SQL/code, statistics, machine learning, etc.) and learn new skills. Operates under the supervision and mentorship of more experienced managers and data scientists.Key Responsibilities30% Executes existing reporting and analytical responsibilities20% Leverages data analytics tools to create new dashboards, reports, and any additional ad-hoc requests20% Ensures the quality of work output by displaying a keen attention to detail20% Develops additional technical competencies and subject matter expertise within core functional group10% Presents findings in easily understood ways, focuses on how the data analytics fits into the bigger pictureDirect Manager/Direct ReportsThis postion reports to ManagerThis position has no Direct ReportsTravel RequirementsTypically requires overnight travel less than 10% of the time.Physical RequirementsMost of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.Working ConditionsLocated in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.Minimum QualificationsMust be eighteen years of age or older.Must be legally permitted to work in the United States.Preferred QualificationsWork experience with SQL Server, Teradata, Oracle, or comparable database systems1-3 years work experience in data mining, statistical analysis, auditing, and/or forecasting.Prior direct experience in analyzing the relevant subject matter (e.g. Supply Chain, Merchandising, Operations, etc.)B.S. in Computer Science, Math, Engineering, Finance or related quantitative fieldMinimum EducationThe knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.Preferred EducationNo additional educationMinimum Years Of Work Experience0Preferred Years Of Work ExperienceNo additional years of experienceMinimum Leadership ExperienceNonePreferred Leadership ExperienceNoneCertificationsNoneCompetenciesCritical thinking skills to identify the strengths and weaknesses of alternative solutions; ability to understand and foresee implications of new information for current and future problems solving.An unquenchable intellectual curiosity for getting at the underlying story being told within the data.Strong written and verbal communications skills. Ability to persuade, inform, and influence others based on findings. A track record of taking complex results and communicating them in an easily understood way.Superior interpersonal skills and ability to collaborate actively and work in a team environment.Ability to quickly learn and adapt to new technologies, tools, and techniques.Show moreShow lessPosition: Data Profiler / Data Analyst(99% remote)Location: Houston, TXDuration: 12+ monthsVisa: GC,USCExperience: 12+yearsSkillsData Analysis.SQL.Show moreShow lessCompany DescriptionOUR STORYEquinox Group is a high growth collective of the world's most influential, experiential, and differentiated lifestyle brands. We restlessly seek what is next for maximizing life - and boldly grow the lifestyle brands and experiences that define it. In addition to Equinox, our other brands,Blink, Pure Yoga, SoulCycle, Equinox Hotels and Equinox Mediaare all recognized for inspiring and motivating members and employees to maximize life. Our portfolio of brands is recognized globally with locations within every major city across the United States in addition to London, Toronto, and Vancouver.OUR CODEWe are passionate about high-performance living and we practice what we preach – investing time in our own health and fitness. We believe that everyone has untapped potential within them and it takes a disruptive approach to unleash it. We dream big and don’t settle for the status quo. We sweat the details. We never accept less than 110% to help each other deliver the Equinox experience and enable our members to get great results. We are obsessed with what’s new, what’s now, what’s next. Never following, always leading, living ahead of the moment in fashion, culture and consumer behavior. We aren’t just a company; we’re a community vested in each other’s success. We value humility and a team approach at every level of the company.If you are a high performing individual who is passionate about winning and inspiring others then we are excited to discuss career opportunities\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b390c7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"At Netflix, our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with.Who are you?You strive to write elegant code, and you're comfortable with picking up new technologies independentlyYou are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQLYou enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning modelsYou have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modelingYou are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasetsYou have an eye for detail, good data intuition, and a passion for data qualityYou appreciate the importance of great documentation and data debugging skillsYou relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedbackYou are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risksAt Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.The overall market range for roles in this area of Netflix is typically $150,000 - $750,000This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.Show moreShow lessNetflix is the world's leading internet entertainment service with over 220+ million memberships in over 190 countries enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. And as of November 2022, we added an advertisement branch to our business, making Netflix service accessible to an even broader member base with ad-supported plans!Ads Data Engineering team sits at the core of building a data ecosystem that will power Netflix’s understanding and decision-making about what impact ads have on our business. It is part of a larger data engineering org within Content and Studio Data Engineering horizontal, with a strong sense of engineering community that fosters technical and personal growth. This team’s main focus is to build rich, connected, and easily accessible data about ad inventories, forecasting, targeting, and much more. Core data about ads is used across multiple business areas and functions, from getting informative analytics to feature development for statistical models. The scope of this team’s work is rapidly growing and there are many opportunities for impacting Netflix’s journey into advertisement. We are looking for a passionate, mature, and curious Data Engineer, with ad ecosystem experience, to contribute to the team’s impact in a quickly\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_data[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6998c39",
   "metadata": {},
   "source": [
    "### Data Cleaning & stop words removal\n",
    "\n",
    "(For detailed explanation check my project here - https://github.com/Abhishek-Dxt/NLP_data_roles/blob/master/NLP_data_roles.ipynb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad668375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(doc):\n",
    "    symbols = '!\"#$%&()*+-/:;<=>?@^_`{|}~'\n",
    "    for i in symbols:\n",
    "        doc = doc.replace(i,\" \")\n",
    "    content = [word.lower() for word in doc.split()]\n",
    "    return \" \".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f60b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_data = data_cleaner(da_data)\n",
    "ds_data = data_cleaner(ds_data)\n",
    "ml_data = data_cleaner(ml_data)\n",
    "de_data = data_cleaner(de_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e032ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "english_stop_words = spacy.load('en_core_web_sm')\n",
    "stopwords = english_stop_words.Defaults.stop_words\n",
    "sw = set(STOPWORDS)\n",
    "stopwords.update(sw)\n",
    "\n",
    "def stopword_remover(doc, Stopwords):\n",
    "    content = [word for word in doc.split() if word not in Stopwords]\n",
    "    return \" \".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13159718",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_no_sw = stopword_remover(da_data, stopwords)\n",
    "ds_no_sw = stopword_remover(ds_data, stopwords)\n",
    "ml_no_sw = stopword_remover(ml_data, stopwords)\n",
    "de_no_sw = stopword_remover(de_data, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd291a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = da_no_sw + ds_no_sw + ml_no_sw + de_no_sw\n",
    "words_set = set()\n",
    "words = all_data.split(' ')\n",
    "words.remove('.')\n",
    "words_set = words_set.union(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f15a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "def custom_lemmatizer(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = nltk.word_tokenize(data)\n",
    "    lemmatized_data = ' '.join([lemmatizer.lemmatize(w) for w in lemma_list])\n",
    "    return lemmatized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "393141c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = custom_lemmatizer(ml_no_sw)\n",
    "ds_data = custom_lemmatizer(ds_no_sw)\n",
    "da_data = custom_lemmatizer(da_no_sw)\n",
    "de_data = custom_lemmatizer(de_no_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb55a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stop_words = {'•','work','tools','hiring', 'ability','teams','skills','strong', 'intern', 'msc', 'knowledge','working','product','systems','g','e','support','preferred','understanding','solutions','qualifications','large','new','responsibilities','degree','including','jobs','hiring','career','workforce','recruiting','recruitment','identify','related','relevant','create','role','end','methods','problems','technical','use','results','impact','like','required','time','provide','performance','learn','sources','drive','quality','building','help','processes','requirements','best','projects','improve','techniques','da','excellent','project','effective','ensure','people','3','practices','5','information','familiarity','problem','multiple','high','key','existing','proficiency','complex','define','partners','you’ll','tasks','apply','packages','computing','ds','following','maintain','findings','qlik', '2','highly','interpret','understand','continuous','skills,','platforms','clearly','oriented','good','growth','need','deliver','different','written','closely','way','systems,','feedback','minimum','non','successful','conduct','solving','real','fast','questions','job','trends','users','perform','basic','needs','solve','internal','based','able','opportunities','responsible','4','1','methods', 'technologies', 'engineering', 'you', 'research', 'software', 'develop','programming','training','implement', 'internship', 'programs', 'pma', 'systemart', 'canon', 'vodori', 'pilot', 'loréal', 'disney', 'hsbc', 'ubs', 'meta', 'acretrader', 'walmart', 'microsoft', 'yahoo', 'ad', 'astra', 'stripe', 'cisco', 'growsquares', 'capital',  'synechron', 'bastian', 'soluitons', 'samsung', 'america', 'eversight', 'bluevine', 'wework', 'overstock', 'beacons', 'qualcomm', 'fieldcore', 'hellofresh'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b06c4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_data = stopword_remover(da_data, more_stop_words)\n",
    "ds_data = stopword_remover(ds_data, more_stop_words)\n",
    "ml_data = stopword_remover(ml_data, more_stop_words)\n",
    "de_data = stopword_remover(de_data, more_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54da4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_filter(s):\n",
    "    return len(s) > 5\n",
    "\n",
    "def dataframe_creator(data, role):\n",
    "    data_list = data.split(\".\")\n",
    "    data_list = [i.strip() for i in filter(len_filter,data_list)]\n",
    "    df = pd.DataFrame(data=data_list, columns=['Role_Description'])\n",
    "    df['Role'] = role\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a62b0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dataset = dataframe_creator(ds_data, 'Data Scientist')\n",
    "da_dataset = dataframe_creator(da_data, 'Data Analyst')\n",
    "ml_dataset = dataframe_creator(ml_data, 'Machine Learning')\n",
    "de_dataset = dataframe_creator(de_data, 'Data Engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce1a11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role_Description</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking forwe tasked attracting skilled experi...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>looking individual facilitate development cutt...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r d team plan experiment , process , analyze ,...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>additional responsibility include devising exp...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type person looking embrace “ start mindset ” ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>restful api communicate data management compon...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>team cutting edge cyber technology continuousl...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>find lockheed martin ’ s cyber capabilities</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>to promote sharing idea , lockheed martin fost...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>show moreshow</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Role_Description            Role\n",
       "0     looking forwe tasked attracting skilled experi...  Data Scientist\n",
       "1     looking individual facilitate development cutt...  Data Scientist\n",
       "2     r d team plan experiment , process , analyze ,...  Data Scientist\n",
       "3     additional responsibility include devising exp...  Data Scientist\n",
       "4     type person looking embrace “ start mindset ” ...  Data Scientist\n",
       "...                                                 ...             ...\n",
       "2101  restful api communicate data management compon...   Data Engineer\n",
       "2102  team cutting edge cyber technology continuousl...   Data Engineer\n",
       "2103        find lockheed martin ’ s cyber capabilities   Data Engineer\n",
       "2104  to promote sharing idea , lockheed martin fost...   Data Engineer\n",
       "2105                                      show moreshow   Data Engineer\n",
       "\n",
       "[2106 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [ds_dataset,da_dataset, ml_dataset, de_dataset]\n",
    "data_combined = pd.concat(datasets)\n",
    "data_combined = data_combined.reset_index(drop=True)\n",
    "data_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db014f1c",
   "metadata": {},
   "source": [
    "## Building Machine Learning Model to predict a role given a skill/set of skills - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38432983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_combined['Role_Description'], data_combined['Role'], random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c78fcfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3152e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Model -\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_cv, y_train)\n",
    "predictions = naive_bayes.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3a6e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6091081593927894\n",
      "Precision score:  0.6068353889554376\n",
      "Recall score:  0.6091081593927894\n",
      "Confusion Matrix:\n",
      " [[ 81  29  15  11]\n",
      " [  8 125  12  21]\n",
      " [ 19  33  38  20]\n",
      " [  6  20  12  77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "print('Accuracy score: ', accuracy_score(y_test, predictions))\n",
    "print('Precision score: ', precision_score(y_test, predictions, average='weighted'))\n",
    "print('Recall score: ', recall_score(y_test, predictions, average='weighted'))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd2691f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model - \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_cv, y_train)\n",
    "predictions_lr = lr.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5db238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6166982922201139\n",
      "Precision score:  0.6130599550809478\n",
      "Recall score:  0.6166982922201139\n",
      "Confusion Matrix:\n",
      " [[ 86  30  11   9]\n",
      " [ 13 122  13  18]\n",
      " [ 21  31  40  18]\n",
      " [ 10  19   9  77]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, predictions_lr))\n",
    "print('Precision score: ', precision_score(y_test, predictions_lr, average='weighted'))\n",
    "print('Recall score: ', recall_score(y_test, predictions_lr, average='weighted'))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test,predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "258bf793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow - Machine Learning\n",
      "Prediction probability for classes - DA, DS, ML, DE: [0.09143108 0.10310993 0.24286357 0.56259541]\n",
      "mapreduce - Data Engineer\n",
      "Prediction probability for classes - DA, DS, ML, DE: [0.22672578 0.32742242 0.1918936  0.2539582 ]\n",
      "tableau - Data Analyst\n",
      "Prediction probability for classes - DA, DS, ML, DE: [0.55538051 0.20877381 0.10927615 0.12656954]\n",
      "sql - Data Engineer\n",
      "Prediction probability for classes - DA, DS, ML, DE: [0.33649085 0.531261   0.10924258 0.02300557]\n"
     ]
    }
   ],
   "source": [
    "skills = [\"tensorflow\", \"mapreduce\", \"tableau\", \"sql\"]\n",
    "for skill in skills:\n",
    "    user_input = cv.transform([skill]).toarray()\n",
    "    print(skill,'-',naive_bayes.predict(user_input)[0]) \n",
    "    print('Prediction probability for classes - DA, DS, ML, DE:',naive_bayes.predict_proba(user_input)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ee641",
   "metadata": {},
   "source": [
    "## Evaluating Results -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99530480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(skills):\n",
    "    data = cv.transform([skills]).toarray()\n",
    "    probas = naive_bayes.predict_proba(data)\n",
    "    # print(probas[0][0])\n",
    "    if probas[0][0] == 0.3074074074074075:\n",
    "        return(\"Give relevant input\")\n",
    "    classes = naive_bayes.classes_\n",
    "    print(\"Ideal Role: \", naive_bayes.predict(data)[0])\n",
    "    for class_name, proba in zip(classes, probas[0]):\n",
    "        print(f\"{class_name}: {round(proba*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef6071fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Data Engineer\n",
      "Data Analyst: 6.39%\n",
      "Data Engineer: 84.76%\n",
      "Data Scientist: 4.91%\n",
      "Machine Learning: 3.93%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'big data'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1ef222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Data Scientist\n",
      "Data Analyst: 20.31%\n",
      "Data Engineer: 22.9%\n",
      "Data Scientist: 35.96%\n",
      "Machine Learning: 20.83%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'statistics'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afd94f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Data Analyst\n",
      "Data Analyst: 54.4%\n",
      "Data Engineer: 17.53%\n",
      "Data Scientist: 24.08%\n",
      "Machine Learning: 3.99%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'dashboard'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5a02217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Machine Learning\n",
      "Data Analyst: 8.26%\n",
      "Data Engineer: 9.32%\n",
      "Data Scientist: 14.63%\n",
      "Machine Learning: 67.79%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'pytorch'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fb16bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Data Engineer\n",
      "Data Analyst: 14.67%\n",
      "Data Engineer: 45.5%\n",
      "Data Scientist: 9.74%\n",
      "Machine Learning: 30.09%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'cloud'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "693ab22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Role:  Data Scientist\n",
      "Data Analyst: 22.93%\n",
      "Data Engineer: 12.93%\n",
      "Data Scientist: 40.61%\n",
      "Machine Learning: 23.52%\n"
     ]
    }
   ],
   "source": [
    "user_input = 'r'\n",
    "output(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f77987",
   "metadata": {},
   "source": [
    "### Saving the model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3429c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "final_model = {'vectorizer': cv,\n",
    "              'model': naive_bayes}\n",
    "\n",
    "pickle.dump(final_model, open('saved_model.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
